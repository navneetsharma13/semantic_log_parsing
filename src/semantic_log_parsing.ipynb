{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from config import config\n",
    "from gpt_model import get_completion_from_gpt\n",
    "from claude import get_completion_from_claude\n",
    "from format_output import Format_output\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ROOT_DIR to your repository root.\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "# Set the DATA_DIR to the directory where your data resides.\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data/loghub_2k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_path = os.path.join(ROOT_DIR, 'results')\n",
    "\n",
    "now_time = datetime.datetime.now()\n",
    "date_string = \"Semantic_\" + now_time.strftime('%Y-%m-%d-%H-%M-%S')\n",
    "save_dir_separator = \"Semantic_\" + now_time.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "save_dir_now = os.path.join(save_dir_path, save_dir_separator)\n",
    "raw_save_dir = os.path.join(save_dir_now, \"semantic_raw_results/\")\n",
    "Path(raw_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "semantic_raw_output_file_name = 'semantic_output.txt'\n",
    "semantic_raw_output_file_path = raw_save_dir + semantic_raw_output_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "ground_truth_file_path = os.path.join(DATA_DIR, \"sample_ground_truth_template.csv\")\n",
    "# processed_output_file_path = os.path.join(ROOT_DIR, 'results/20241127211340/formatted_results/output_processed.txt')\n",
    "raw_log_file_path = os.path.join(DATA_DIR, \"sample_combined_raw_logs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth data\n",
    "ground_truth_df = pd.read_csv(ground_truth_file_path)\n",
    "ground_truth_templates = ground_truth_df['EventTemplate'].tolist()\n",
    "ground_truth_systems = ground_truth_df['System'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw log messages\n",
    "with open(raw_log_file_path, 'r') as raw_file:\n",
    "    raw_logs = [line.strip() for line in raw_file.readlines()]\n",
    "\n",
    "# # Load processed output data (before semantic enhancement)\n",
    "# with open(processed_output_file_path, 'r') as processed_file:\n",
    "#     processed_templates_before = [line.strip() for line in processed_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the lists are of the same length for comparison\n",
    "min_length = min(len(ground_truth_templates), len(processed_templates_before), len(raw_logs))\n",
    "ground_truth_templates = ground_truth_templates[:min_length]\n",
    "processed_templates_before = processed_templates_before[:min_length]\n",
    "raw_logs = raw_logs[:min_length]\n",
    "ground_truth_systems = ground_truth_systems[:min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Prompt: Analyze the log message timestamped on Sun Dec 04 04:47:44 2005, indicating a notice from workerEnv.init() confirming successful initialization with workers2.properties located at /etc/httpd/conf/. Evaluate the accuracy of the previous template extraction based on this information.\n",
      "Sure! Here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Enhance the template extraction prompt to accurately capture the context and meaning of the log message: \n",
      "Log Message: 2573624 node-148 unix.hw net.niff.up 1074131743 1 NIFF: node node-148 reports network connection availability on network 5.5.226.0 via interface alt0.\n",
      "Match Status: False. Refine the prompt to improve template extraction for this log message.\"\n",
      "Prompt: Extract the essential details from the log message to understand the kernel command line configuration. Log Message: Jul 27 14:41:57 combo kernel: Kernel command line: ro root=LABEL=/ rhgb quiet.\n",
      "Prompt: Improve the template extraction for the log message \"Jul 27 14:41:59 combo kernel: apm: BIOS version 1.2 Flags 0x03 (Driver version 1.16ac)\" by providing a more contextually relevant and semantically meaningful prompt.\n",
      "Sure! Here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Extract essential context and meaning from the log message: 2015-07-31 15:31:42,213 - INFO [QuorumPeer[myid=1]/0:0:0:0:0:0:0:0:2181:QuorumPeer@738] - FOLLOWING. Verify if the previous template extraction was correct (Match Status: True).\"\n",
      "Sure! Here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Extract essential information from the log message related to a fatal RAS KERNEL incident on June 14, 2005, at 10:37:26. The machine state register value is 0x00002000. Previous template extraction was incorrect. Provide a structured format for capturing the key details.\"\n",
      "Revised Prompt: \n",
      "Based on the provided log message, please enhance the prompt to better capture the essential context and meaning for template extraction. \n",
      "\n",
      "Log Message: \n",
      "1123614572 2005.08.09 R00-M0-N6-C:J03-U11 2005-08-09-12.09.32.252222 R00-M0-N6-C:J03-U11 RAS KERNEL FATAL rts tree/torus link training failed: wanted: B C X+ X- Y+ Y- Z+ Z- got: B C X- Y- Z+ Z- \n",
      "\n",
      "Match Status: False. \n",
      "\n",
      "Please provide a more effective prompt for extracting the semantic meaning from the log message.\n",
      "Sure! Here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Extract the essential details from the log message related to YARN_AM_RM_TOKEN in the context of an application attempt. Log Message: 2015-10-18 18:01:48,963 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 20 cluster_timestamp: 1445144423722 } attemptId: 1 } keyId: -127633188) Match Status: True.\"\n",
      "Based on the provided log message, here is an enhanced prompt for better extraction of semantic meaning:\n",
      "\n",
      "\"Enhance the log message extraction prompt to capture the essential context and meaning effectively. Log Message: 2015-10-18 18:01:53,900 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1445144423722_0020, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0020/job_1445144423722_0020_1.jhist. Match Status: False. Please provide a refined prompt for template extraction.\"\n",
      "Sure! Here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Enhance the log message extraction prompt to accurately capture the context and meaning of the following log message: \n",
      "2015-10-18 18:06:03,856 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connection to server 'msra-sa-41:8030'. Previous attempts: 0. Retry policy: RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS).\"\n",
      "\n",
      "This prompt provides more clarity by specifying the action of \"retrying connection,\" mentioning the server being connected to, and detailing the retry attempts and policy for better template extraction.\n",
      "Enhanced Prompt: Analyze the log message \"Jul 1 09:45:08 calvisitor-10-105-160-95 kernel[0]: ARPT: 621686.164365: wl0: setup_keepalive: Local port: 62614, Remote port: 443\" with a focus on extracting key details related to the setup_keepalive function, including the local port (62614) and remote port (443). Evaluate the accuracy of the previous template extraction based on this log message.\n",
      "Enhanced Prompt: Analyze the log message \"Jul 1 20:23:09 calvisitor-10-105-163-202 cloudd[326]: SecOSStatusWith error:[-50] Error Domain=NSOSStatusErrorDomain Code=-50 'query missing class name' (paramErr: error in user parameter list) UserInfo={NSDescription=query missing class name}\" to extract key details accurately for template creation.\n",
      "Enhanced Prompt:\n",
      "Based on the provided log message, please create a template that accurately captures the essential context and meaning. Log Message: Jul 3 00:41:11 authorMacBook-Pro syslogd[44]: Configuration Notice: ASL Module \"com.apple.performance\" claims selected messages. Those messages may not appear in standard system log files or in the ASL database. Match Status: True.\n",
      "Sure, here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Enhance the template extraction prompt to effectively capture the essential context and meaning of the log message: \n",
      "'Jul 3 17:37:47 calvisitor-10-105-160-184 kernel[0]: **** [IOBluetoothFamily][ProcessBluetoothTransportShowsUpActionWL] -- calling IOBluetoothFamily's registerService() -- 0x5fd0 -- 0x9a00 -- 0x6800 ****' \n",
      "Match Status: False. Please provide a more refined prompt for accurate template extraction.\"\n",
      "Enhanced Prompt: Extract the time taken for hibernate_newruntime_map operation, along with the status of IOPolledFilePollersOpen and ml_get_interrupts_enabled, from the kernel log message timestamped on Jul 5 at 10:31:18 on the calvisitor-10-105-163-10 machine.\n",
      "Sure! Here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Given the log message 'Jul 6 10:52:50 calvisitor-10-105-163-253 ChromeExistion[36852]: url host = www.baidu.com', please provide a template that accurately captures the context and meaning of the log message. The previous extraction was correct (Match Status: True). Your task is to enhance the prompt for more effective template extraction.\"\n",
      "Sure! Here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Extract the arranged view frame dimensions from the log message recorded on Jul 8 at 06:46:42 by the application WeChat running on the device calvisitor-10-105-162-124. The log message indicates the view frame size as {{0, 0}, {260, 877}}. Previous extraction attempt was unsuccessful. Please provide an improved template for accurate data extraction.\"\n",
      "Sure! Here is an enhanced prompt for better extraction of semantic meaning based on the given log message:\n",
      "\n",
      "\"Enhance the template extraction prompt to accurately capture the context and meaning of the log message: \n",
      "Timestamp: 20171223-22:19:58:505, Module: Step_FlushableStepDataCache, ID: 30002312, Action: InsertCallBack() onSuccess, Type: 0, Data: true. Previous extraction match status: False. Please provide a more effective prompt for template extraction.\"\n",
      "Prompt: Improve the template extraction for the log message \"Dec 10 09:32:20 LabSZ sshd[24680]: pam_unix(sshd:session): session opened for user fztu by (uid=0)\" by providing a more contextually relevant and semantically meaningful prompt. Consider the log message content and aim to extract key details effectively.\n",
      "Revised Prompt: Based on the log message provided, please enhance the prompt to improve the extraction of essential context and meaning for template extraction. Log Message: 081110 211541 18 INFO dfs.DataNode: 10.250.15.198:50010 Starting thread to transfer block blk_4292382298896622412 to 10.250.15.240:50010 Match Status: False.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m match_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gt_template \u001b[38;5;241m==\u001b[39m processed_template \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m new_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are provided with a log message along with a match status indicating whether the previous template\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m                 extraction was correct. Your task is to enhance the prompt for better extraction of semantic meaning \u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m                 based on the given log message. Log Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Match Status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatch_status\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please reformulate \u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m                 the prompt to capture the essential context and meaning of the log message in a more effective way for \u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m                 template extraction.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m enhanced_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion_from_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m enhanced_prompts\u001b[38;5;241m.\u001b[39mappend(enhanced_prompt)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/.venv/lib/python3.9/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/.venv/lib/python3.9/site-packages/tenacity/__init__.py:485\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    484\u001b[0m     retry_state\u001b[38;5;241m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 485\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m~/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/.venv/lib/python3.9/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 1: Reformulate log messages with semantic understanding\n",
    "counter=0\n",
    "enhanced_prompts = []\n",
    "enhanced_prompts_file_path = os.path.join(save_dir_now, \"enhanced_prompts.txt\")\n",
    "for raw_log, gt_template, processed_template in zip(raw_logs, ground_truth_templates, processed_templates_before):\n",
    "    match_status = \"True\" if gt_template == processed_template else \"False\"\n",
    "    new_prompt = f\"\"\"You are provided with a log message along with a match status indicating whether the previous template\n",
    "                     extraction was correct. Your task is to enhance the prompt for better extraction of semantic meaning \n",
    "                     based on the given log message. Log Message: {raw_log} Match Status: {match_status}. Please reformulate \n",
    "                     the prompt to capture the essential context and meaning of the log message in a more effective way for \n",
    "                     template extraction.\"\"\"\n",
    "    \n",
    "    enhanced_prompt = get_completion_from_gpt(new_prompt)\n",
    "    enhanced_prompts.append(enhanced_prompt)\n",
    "    if counter % 50 == 0:\n",
    "        print(counter)\n",
    "\n",
    "    counter+=1\n",
    "    with open(enhanced_prompts_file_path, 'a') as enhanced_file:\n",
    "        enhanced_file.write(enhanced_prompt + '')\n",
    "\n",
    "# Save all enhanced prompts to a file\n",
    "print(f\"Enhanced prompts saved to: {enhanced_prompts_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953\n"
     ]
    }
   ],
   "source": [
    "print(len(enhanced_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic log templates saved to: /Users/navneetsharma/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/results/Semantic_20241128091624/semantic_raw_results/semantic_output.txt\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate log template using zero-shot learning\n",
    "counter = 0\n",
    "enhanced_templates = []\n",
    "semantic_log_template_output_file_path = semantic_raw_output_file_path\n",
    "for raw_log, enhanced_prompt in zip(raw_logs, enhanced_prompts):\n",
    "    counter+=1\n",
    "    semantic_prompt = f\"\"\"You will be provided with a log message delimited by <MSG> and </MSG>. \n",
    "    You are also provided with a new prompt that has the semantic undertanding of the raw log given. New prompt: {enhanced_prompt}. \n",
    "    \n",
    "    The log message typically consists of two parts: \n",
    "    1. Template - message body, that contains constant strings (or keywords) describing the system events; \n",
    "    2. Parameters/Variables - dynamic variables, which reflect specific runtime status.\n",
    "    You must identify and abstract all the dynamic variables in the log message with suitable placeholders inside angle brackets to extract the corresponding template.\n",
    "    You must output the template corresponding to the log message. Print only the input log's template surrounded by <TPL> and </TPL>. \n",
    "    Never print an explanation of how the template is constructed.\n",
    "    Here are a few examples of log messages (labeled with Q:) and corresponding templates (labeled with A:):\n",
    "\n",
    "    Q: <MSG>[081109 204453 34 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.11.85:50010 is added to blk_2377150260128098806 size 67108864]</MSG>\n",
    "    A: <TPL>[BLOCK* NameSystem.addStoredBlock: blockMap updated: <*>:<*> is added to <*> size <*>]</TPL>\n",
    "\n",
    "    Q: <MSG>- 1129734520 2005.10.19 R17-M0-N0-I:J18-U01 2005-10-19-08.08.40.058960 R17-M0-N0-I:J18-U01 RAS KERNEL INFO shutdown complete</MSG>\n",
    "    A: <TPL>shutdown complete</TPL>\n",
    "\n",
    "    Q: <MSG>20231114T101914E ERROR 14 while processing line 123: cannot find input '42'</MSG>\n",
    "    A: <TPL>ERROR <*> while processing line <*>: cannot find input <*></TPL>\n",
    "\n",
    "    Q: <MSG>2023-01-14 23:05:14 INFO: Reading data from /user/input/file.txt</MSG>\n",
    "    A: <TPL>Reading data from <*> </TPL>\n",
    "    Here is the input log message: <MSG>{raw_log}</MSG>\n",
    "    Please print the corresponding template.\n",
    "    \"\"\"\n",
    "    response = get_completion_from_gpt(semantic_prompt)\n",
    "    enhanced_templates.append(response)\n",
    "    # with open(semantic_log_template_output_file_path, 'a') as semantic_file:\n",
    "    #     semantic_file.write(response + '')\n",
    "    if counter == 50:\n",
    "        break    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic log templates saved to: /Users/navneetsharma/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/results/Semantic_20241128091624/semantic_raw_results/semantic_output.txt\n"
     ]
    }
   ],
   "source": [
    "# save and format output data in a csv file\n",
    "Format_output.save_raw_output(semantic_log_template_output_file_path, enhanced_templates)\n",
    "# Save all semantic log templates to a file\n",
    "print(f\"Semantic log templates saved to: {semantic_log_template_output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed output saved to: /Users/navneetsharma/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/results/Semantic_20241128091624/semantic_raw_results/semantic_output.txt\n"
     ]
    }
   ],
   "source": [
    "# convert raw output into formatted file \n",
    "Format_output.remove_TPL_from_output(semantic_log_template_output_file_path, semantic_log_template_output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
