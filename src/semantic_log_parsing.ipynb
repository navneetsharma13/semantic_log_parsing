{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from config import config\n",
    "from gpt_model import get_completion_from_gpt\n",
    "from claude import get_completion_from_claude\n",
    "from format_output import Format_output\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ROOT_DIR to your repository root.\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "# Set the DATA_DIR to the directory where your data resides.\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data/loghub_2k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_path = os.path.join(ROOT_DIR, 'results')\n",
    "\n",
    "now_time = datetime.datetime.now()\n",
    "date_string = \"Semantic_\" + now_time.strftime('%Y-%m-%d-%H-%M-%S')\n",
    "save_dir_separator = \"Semantic_\" + now_time.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "save_dir_now = os.path.join(save_dir_path, save_dir_separator)\n",
    "raw_save_dir = os.path.join(save_dir_now, \"semantic_raw_results/\")\n",
    "Path(raw_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "semantic_template_file_name = 'semantic_output.txt'\n",
    "variables_output_file_name = 'variables_output.txt'\n",
    "semantic_template_output_file_path = raw_save_dir + semantic_template_file_name\n",
    "variables_output_file_path = raw_save_dir + variables_output_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "ground_truth_file_path = os.path.join(DATA_DIR, \"sample_ground_truth_template.csv\")\n",
    "raw_log_file_path = os.path.join(DATA_DIR, \"sample_combined_raw_logs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth data\n",
    "ground_truth_df = pd.read_csv(ground_truth_file_path)\n",
    "ground_truth_log_templates = ground_truth_df['EventTemplate'].tolist()\n",
    "ground_truth_variable_templates = ground_truth_df['VariableTemplate'].tolist()\n",
    "ground_truth_systems = ground_truth_df['System'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw log messages\n",
    "with open(raw_log_file_path, 'r') as raw_file:\n",
    "    raw_logs = [line.strip() for line in raw_file.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: <TPL> Initialization of worker environment successful for workers2 properties file at /etc/httpd/conf/workers2.properties. </TPL>\n",
      "10: <TPL> High temperature warning on gige5 interface. </TPL>\n",
      "20: <TPL> Command has been aborted. </TPL>\n",
      "30: <TPL> CPU has an L2 cache size of 256K. </TPL>\n",
      "40: <TPL> Connection to tcpconn4.tencent.com:80 through proxy proxy.cse.cuhk.edu.hk:5070 failed due to unexpected closure by the proxy server. </TPL>\n",
      "50: <TPL> autopurge.snapRetainCount set to 3 </TPL>\n",
      "60: <TPL>RAS KERNEL FATAL disable store gathering</TPL>\n",
      "70: <TPL> Z coordinate exceeds physical dimension in node map file. </TPL>\n",
      "80: <TPL> Shuffle port for a specific task attempt in a Hadoop MapReduce job is assigned the port number 13562. </TPL>\n",
      "90: <TPL>Path not allowed in target domain for Safari SearchHelper service due to missing bundle service in requestor's bundle.</TPL>\n",
      "100: <TPL> Display woke up notification posted by WindowServer. </TPL>\n",
      "110: <TPL> insertHiHealthData() bulkSaveDetailHiHealthData fail </TPL>\n",
      "\n",
      "<TPL> errorCode = 4, errorMessage = ERR_DATA_INSERT </TPL>\n",
      "120: <TPL> User requested to close the SSH connection. </TPL>\n",
      "130: <TPL> Multiple authentication failures for user 'root' from IP address 5.36.59.76. </TPL>\n",
      "140: <TPL> Reading broadcast variable 9 took 160 ms. </TPL>\n",
      "150: <TPL> Block added to blockMap with IP and size information. </TPL>\n",
      "160: <TPL> Request sent to delete a specific block from a data node with IP address 10.250.18.114. </TPL>\n",
      "170: <TPL> Instance b9000564-fe1a-409b-b8cc-1e88b294cd1d took 19.84 seconds to build. </TPL>\n",
      "180: <TPL> Detected i8042 AUX port configuration at memory addresses 0x60,0x64 with IRQ 12 on tbird-admin1. </TPL>\n",
      "190: <TPL> ACPI: LAPIC enabled. </TPL>\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Reformulate log messages with semantic understanding\n",
    "counter=0\n",
    "enhanced_prompts = []\n",
    "enhanced_prompts_file_path = os.path.join(save_dir_now, \"enhanced_prompts.txt\")\n",
    "for raw_log in raw_logs:\n",
    "    new_prompt=f\"\"\"You are provided with a log message. Your task is to understand and extract the meaning behind the semi-structured log message.\n",
    "                      \n",
    "                    Log message: {raw_log}. \n",
    "\n",
    "                    A log message usually contains a header that is automatically produced by the logging framework, including information such as timestamp, class, and logging level (INFO, DEBUG, WARN etc.).\n",
    "                    Ignore all these details and just understand meaning behind the natural languagae text which is in the log content.\n",
    "\n",
    "                    The log content typically consists of many parts: \n",
    "                    1. Template - message body, that contains constant strings (or keywords) describing the system events; \n",
    "                    2. Parameters/Variables - dynamic variables, which reflect specific runtime status;\n",
    "\n",
    "                    Please capture the essential context and meaning from the log message to understand the reasoning behind each raw log.\n",
    "                    Provide only the meaning in 20-25 words from each log message surrounded by <TPL> and </TPL>. \n",
    "                    Never provide an explanation of how the meaning is constructed.\n",
    "                \"\"\"\n",
    "    \n",
    "    enhanced_prompt = get_completion_from_gpt(new_prompt)\n",
    "    enhanced_prompts.append(enhanced_prompt)\n",
    "    if counter % 10 == 0:\n",
    "        print(f'{counter}: {enhanced_prompt}')\n",
    "    counter+=1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "print(len(enhanced_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic log templates saved to: /Users/navneetsharma/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/results/Semantic_20241203153952/enhanced_prompts.txt\n"
     ]
    }
   ],
   "source": [
    "# save and format output data in a csv file\n",
    "Format_output.save_raw_output(enhanced_prompts_file_path, enhanced_prompts)\n",
    "\n",
    "# Save all semantic log templates to a file\n",
    "print(f\"Semantic log templates saved to: {enhanced_prompts_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed output saved to: /Users/navneetsharma/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/results/Semantic_20241203153952/enhanced_prompts.txt\n"
     ]
    }
   ],
   "source": [
    "# convert raw output into formatted file \n",
    "Format_output.remove_TPL_from_output(enhanced_prompts_file_path, enhanced_prompts_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: <TPL>workerEnv.init() ok <*> </TPL>\n",
      "10: <TPL>gige temperature <*> <*> warning</TPL>\n",
      "20: <TPL>Command has been aborted</TPL>\n",
      "30: <TPL>CPU: L2 cache: <*> </TPL>\n",
      "40: <TPL>Could not connect through proxy <*> - Proxy closed the connection unexpectedly.</TPL>\n",
      "50: <TPL>autopurge.snapRetainCount set to <*> </TPL>\n",
      "60: <TPL>FATAL disable store gathering</TPL>\n",
      "70: <TPL>ciod: Z coordinate <*> exceeds physical dimension <*> at line <*> of node map file <*> </TPL>\n",
      "80: <TPL>Shuffle port returned by ContainerManager for attempt_<*>_<*>_<*>_<*> : 13562</TPL>\n",
      "90: <TPL>Path not allowed in target domain for Safari SearchHelper service due to missing bundle service in requestor's bundle.</TPL>\n",
      "100: <TPL>CGXDisplayDidWakeNotification [*]: posting kCGSDisplayDidWake</TPL>\n",
      "110: <TPL>insertHiHealthData() bulkSaveDetailHiHealthData fail errorCode = <*> ,errorMessage = <*></TPL>\n",
      "120: <TPL>Closed due to user request.</TPL>\n",
      "130: <TPL>5 more authentication failures; logname= uid=0 euid=0 tty=ssh ruser= rhost=<*>.net.om  user=root</TPL>\n",
      "140: <TPL>Reading broadcast variable <*> took <*> ms</TPL>\n",
      "150: <TPL>[BLOCK* NameSystem.addStoredBlock: blockMap updated: <*>:<*> is added to <*> size <*>]</TPL>\n",
      "160: <TPL>BLOCK* ask <*>:<*> to delete  blk_<*></TPL>\n",
      "170: <TPL>Took <*> seconds to build instance.</TPL>\n",
      "180: <TPL>serio: i8042 AUX port at 0x*,0x* irq *</TPL>\n",
      "190: <TPL>ACPI: LAPIC (acpi_id[*] lapic_id[*] enabled)</TPL>\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate log template using zero-shot learning\n",
    "counter_1 = 0\n",
    "semantic_based_templates = []\n",
    "for raw_log, enhanced_prompt in zip(raw_logs, enhanced_prompts):\n",
    "    semantic_prompt = f\"\"\"You will be provided with a log message delimited by <MSG> and </MSG>. \n",
    "    You are also provided with the meaning or understanding from the log message as follow: {enhanced_prompt}. \n",
    "    \n",
    "    The log message typically consists of two parts: \n",
    "    1. Template - message body, that contains constant strings (or keywords) describing the system events; \n",
    "    2. Parameters/Variables - dynamic variables, which reflect specific runtime status.\n",
    "    You must identify and abstract all the dynamic variables in the log message with suitable placeholders inside angle brackets to extract the corresponding template.\n",
    "    You must output the template corresponding to the log message. Print only the input log's template surrounded by <TPL> and </TPL>. \n",
    "    Never print an explanation of how the template is constructed.\n",
    "    Here are a few examples of log messages (labeled with Q:) and corresponding templates (labeled with A:):\n",
    "\n",
    "    Q: <MSG>[081109 204453 34 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.11.85:50010 is added to blk_2377150260128098806 size 67108864]</MSG>\n",
    "    A: <TPL>[BLOCK* NameSystem.addStoredBlock: blockMap updated: <*>:<*> is added to <*> size <*>]</TPL>\n",
    "\n",
    "    Q: <MSG>- 1129734520 2005.10.19 R17-M0-N0-I:J18-U01 2005-10-19-08.08.40.058960 R17-M0-N0-I:J18-U01 RAS KERNEL INFO shutdown complete</MSG>\n",
    "    A: <TPL>shutdown complete</TPL>\n",
    "\n",
    "    Q: <MSG>20231114T101914E ERROR 14 while processing line 123: cannot find input '42'</MSG>\n",
    "    A: <TPL>ERROR <*> while processing line <*>: cannot find input <*></TPL>\n",
    "\n",
    "    Q: <MSG>2023-01-14 23:05:14 INFO: Reading data from /user/input/file.txt</MSG>\n",
    "    A: <TPL>Reading data from <*> </TPL>\n",
    "    Here is the input log message: <MSG>{raw_log}</MSG>\n",
    "    Please print the corresponding template.\n",
    "    \"\"\"\n",
    "    response = get_completion_from_gpt(semantic_prompt)\n",
    "    semantic_based_templates.append(response)\n",
    "    \n",
    "    if counter_1 % 10 == 0:\n",
    "        print(f'{counter_1}: {response}')\n",
    "        \n",
    "    counter_1+=1   \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: <TPL>[O O O O TID O O O O LOI O O O O O O O O O]</TPL>\n",
      "10: <TPL>[OID OBN OBN TID OID OBA STC]</TPL>\n",
      "20: <TPL>[O O TID TID OID OID TID]</TPL>\n",
      "30: A: <TPL>[O O O O O O O O CRS:O O O O OBA]</TPL>\n",
      "40: <TPL>[TDA O O O O O O OID O O O O O O O O O O O O O O O O O O O O O O O O O O O O]</TPL>\n",
      "50: <TPL>[O O O O O O O TID O O O O O O O O O O O OBA]</TPL>\n",
      "60: <TPL>[OID OBA OBA TID OTP]</TPL>\n",
      "70: <TPL>[OID OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA OBA\n",
      "80: <TPL>[O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID OID\n",
      "90: <TPL>[O O O O O O O O O O TID O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "100: A: <TPL>[O O O O O O OID O TID O O O]</TPL>\n",
      "110: <TPL>[TDA OBN OID TID OBN OBA STC OTP OTP]</TPL>\n",
      "120: <TPL>[O O O O O O TID O O OID O O O O O O O O]</TPL>\n",
      "130: <TPL>[O O O O O O TID OBA OBA OBA OBA OBA OBA OBA OBN OBN OBN OBN OBN OBN OBN OBN OBN OBN OBN OID]</TPL>\n",
      "140: A: <TPL>[O O O O O O O TID OBA TDA]</TPL>\n",
      "150: A: <TPL>[O O O O O O O O O O O O OID O O O O O O OBA]</TPL>\n",
      "160: <TPL>[O O O O O LOI TID OID OBN]</TPL>\n",
      "170: <TPL>[O O O O O O O O O OID OID OID OID O TDA]</TPL>\n",
      "180: <TPL>[OID OID OID OBN O TDA O O O O O O]</TPL>\n",
      "190: <TPL>[OID OID OID OBN OBN TDA]</TPL>\n"
     ]
    }
   ],
   "source": [
    "counter_1 = 0\n",
    "variable_from_logs = []\n",
    "for raw_log, enhanced_prompt in zip(raw_logs, enhanced_prompts):\n",
    "    semantic_prompt = f\"\"\"You will be provided with a log message delimited by <MSG> and </MSG>. \n",
    "    You are also provided with the meaning or understanding from the log message as follow: {enhanced_prompt}. \n",
    "    \n",
    "    I want you to categorize the variable(s) in each log message as variable template. \n",
    "    The variable should be classified within the category as below:\n",
    "    1. Object ID [OID]\tIdentification information of an object\n",
    "    2. Location Indicator   [LOI]\tLocation information of an object\n",
    "    3. Object Name\t[OBN]\tName of an object\n",
    "    4.Type Indicator\t[TID]\tType information of an object or an action\n",
    "    5. Switch Indicator\t[SID]\tStatus of a switch variable\n",
    "    6. Time or Duration of an Action\t[TDA]\tTime or duration of an action\n",
    "    7. Computing Resources\t[CRS]\tInformation of computing resource\n",
    "    8. Object Amount\t[OBA]\tAmount of an object\n",
    "    9. Status Code\t[STC]\tStatus code of an object or an action\n",
    "    10. Other Parameters\t[OTP]\tOther information does not belong to the above categories]. \n",
    "    \n",
    "\n",
    "\n",
    "    Static words/parts of the log message are to be annotated with O strictly\n",
    "    Organize your variable template within <TPL></TPL> in the following format for each Q: \n",
    "\n",
    "    Q: <MSG>[Jul  1 22:08:16 calvisitor-10-105-163-202 WindowServer[184]: device_generate_desktop_screenshot: authw 0x7fa823c89600(2000), shield 0x7fa8258cac00(2001)]</MSG>\n",
    "    A: <TPL>[O O O O O O O O OID OID OID OID OBA]</TPL>\n",
    "\n",
    "    Q: <MSG>[nova-scheduler.log.1.2017-05-16_13:53:08 2017-05-16 00:00:57.129 25998 INFO nova.scheduler.host_manager [req-d724a3bd-e314-4f81-a41c-460aa91f24ae - - - - -] Successfully synced instances from host 'cp-1.slowvm1.tcloud-pg0.utah.cloudlab.us']</MSG>\n",
    "    A: <TPL>[O O O O O O O O O O O O LOI O LOI OBN O STC O OBA O TDA]</TPL>\n",
    "\n",
    "    Above is an example of our log annotation process. Static words are annotated with O, object ID is annotated with OID, \n",
    "    and two location indicators are annotated with LOI.\n",
    "\n",
    "    Here is the input log message: <MSG>{raw_log}</MSG>\n",
    "    Print only the variable template surrounded by <TPL> and </TPL> and nothing else for each log message. \n",
    "    Never print an explanation of how the variable_template is constructed.\n",
    "    \"\"\"\n",
    "    response = get_completion_from_gpt(semantic_prompt)\n",
    "    variable_from_logs.append(response)    \n",
    "\n",
    "    if counter_1 % 10 == 0:\n",
    "        print(f'{counter_1}: {response}')\n",
    "        \n",
    "    counter_1+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Log templates and Variable templates are saved to: /Users/navneetsharma/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/results/Semantic_20241203153952/semantic_raw_results/\n"
     ]
    }
   ],
   "source": [
    "# save and format output data in a csv file\n",
    "Format_output.save_raw_output(semantic_template_output_file_path, semantic_based_templates)\n",
    "Format_output.save_raw_output(variables_output_file_path, variable_from_logs)\n",
    "# Save all semantic log templates to a file\n",
    "print(f\"Semantic Log templates and Variable templates are saved to: {raw_save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed output saved to: /Users/navneetsharma/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/results/Semantic_20241203153952/semantic_raw_results/semantic_output.txt\n",
      "Processed output saved to: /Users/navneetsharma/Documents/NMBU/MS Data Science @ NMBU/Master's Thesis/semantic_log_parsing/results/Semantic_20241203153952/semantic_raw_results/variables_output.txt\n"
     ]
    }
   ],
   "source": [
    "# convert raw output into formatted file \n",
    "Format_output.remove_TPL_from_output(semantic_template_output_file_path, semantic_template_output_file_path)\n",
    "Format_output.remove_TPL_from_output(variables_output_file_path, variables_output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "processed_log_template_file_path = semantic_template_output_file_path\n",
    "processed_variable_template_file_path = variables_output_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed output data\n",
    "with open(processed_log_template_file_path, 'r') as processed_file:\n",
    "    processed_log_templates = [line.strip() for line in processed_file.readlines()]\n",
    "\n",
    "with open(processed_variable_template_file_path, 'r') as processed_file:\n",
    "    processed_variable_templates = [line.strip() for line in processed_file.readlines()]    \n",
    "\n",
    "# Ensure the lists are of the same length for comparison\n",
    "min_length = min(len(ground_truth_log_templates), len(processed_log_templates), len(processed_variable_templates))\n",
    "ground_truth_log_templates = ground_truth_log_templates[:min_length]\n",
    "ground_truth_variable_templates = ground_truth_variable_templates[:min_length]\n",
    "processed_log_templates = processed_log_templates[:min_length]\n",
    "processed_variable_templates = processed_variable_templates[:min_length]\n",
    "ground_truth_systems = ground_truth_systems[:min_length]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Template Parsing Accuracy: 34.72%\n",
      "Log Template Precision: 35.23%\n",
      "Log Template Recall: 34.72%\n",
      "Log Template F1 Score: 34.89%\n",
      "Variable Template Parsing Accuracy: 0.00%\n",
      "Variable Template Precision: 0.00%\n",
      "Variable Template Recall: 0.00%\n",
      "Variable Template F1 Score: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for processed_log_templates\n",
    "accuracy = accuracy_score(ground_truth_log_templates, processed_log_templates)\n",
    "precision = precision_score(ground_truth_log_templates, processed_log_templates, average='weighted', zero_division=0)\n",
    "recall = recall_score(ground_truth_log_templates, processed_log_templates, average='weighted', zero_division=0)\n",
    "f1 = f1_score(ground_truth_log_templates, processed_log_templates, average='weighted', zero_division=0)\n",
    "\n",
    "# Print evaluation metrics for processed_log_templates\n",
    "print(f\"Log Template Parsing Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Log Template Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Log Template Recall: {recall * 100:.2f}%\")\n",
    "print(f\"Log Template F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Calculate evaluation metrics for processed_variable_templates\n",
    "accuracy = accuracy_score(ground_truth_variable_templates, processed_variable_templates)\n",
    "precision = precision_score(ground_truth_variable_templates, processed_variable_templates, average='weighted', zero_division=0)\n",
    "recall = recall_score(ground_truth_variable_templates, processed_variable_templates, average='weighted', zero_division=0)\n",
    "f1 = f1_score(ground_truth_variable_templates, processed_variable_templates, average='weighted', zero_division=0)\n",
    "\n",
    "# Print evaluation metrics for processed_variable_templates\n",
    "print(f\"Variable Template Parsing Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Variable Template Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Variable Template Recall: {recall * 100:.2f}%\")\n",
    "print(f\"Variable Template F1 Score: {f1 * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correctly Parsed Log Templates per System:\n",
      "Apache: 5\n",
      "HPC: 1\n",
      "Linux: 9\n",
      "Zookeeper: 10\n",
      "BGL: 5\n",
      "Hadoop: 4\n",
      "Mac: 3\n",
      "HealthApp: 6\n",
      "OpenSSH: 6\n",
      "Spark: 12\n",
      "OpenStack: 3\n",
      "Thunderbird: 3\n",
      "Total correctly parsed log templates: 67\n"
     ]
    }
   ],
   "source": [
    "# Calculate correctly parsed log templates for each system\n",
    "correct_parsed_counts = {}\n",
    "for system, gt_template, processed_template in zip(ground_truth_systems, ground_truth_log_templates, processed_log_templates):\n",
    "    if gt_template == processed_template:\n",
    "        if system not in correct_parsed_counts:\n",
    "            correct_parsed_counts[system] = 0\n",
    "        correct_parsed_counts[system] += 1\n",
    "\n",
    "# Print correctly parsed log templates for each system\n",
    "print(\"\\nCorrectly Parsed Log Templates per System:\")\n",
    "total=0\n",
    "for system, count in correct_parsed_counts.items():\n",
    "    total +=count\n",
    "    print(f\"{system}: {count}\")\n",
    "\n",
    "print(f\"Total correctly parsed log templates: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correctly Parsed Variable Templates per System:\n",
      "Total correctly parsed variable templates: 0\n"
     ]
    }
   ],
   "source": [
    "# Calculate correctly parsed variable templates for each system\n",
    "correct_parsed_counts = {}\n",
    "for system, gt_template, processed_template in zip(ground_truth_systems, ground_truth_variable_templates, processed_variable_templates):\n",
    "    if gt_template == processed_template:\n",
    "        if system not in correct_parsed_counts:\n",
    "            correct_parsed_counts[system] = 0\n",
    "        correct_parsed_counts[system] += 1\n",
    "\n",
    "# Print correctly parsed variable templates for each system\n",
    "print(\"\\nCorrectly Parsed Variable Templates per System:\")\n",
    "total=0\n",
    "for system, count in correct_parsed_counts.items():\n",
    "    total +=count\n",
    "    print(f\"{system}: {count}\")\n",
    "\n",
    "print(f\"Total correctly parsed variable templates: {total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
